# RL_MLDL_2425 â€“ Reinforcement Learning Project

This repository contains the full implementation of **Project 4 â€“ Reinforcement Learning** for the *MLDL 2024/25* course at Politecnico di Torino. It includes both:

- The six official tasks required by the project (REINFORCE, Actor-Critic, PPO, UDR)
- A custom project extension based on **Multi-Agent DDPG (MADDPG)** using both UDR and ensemble with distilled policies in a cooperative setting.

---

## ðŸ“ Repository Structure

RL_MLDL_2425/
â”œâ”€â”€ Tasks/                         # Official course tasks
â”‚   â”œâ”€â”€ REINFORCE/                 # REINFORCE with/without baseline
â”‚   â”‚   â”œâ”€â”€ env/
â”‚   â”‚   â”œâ”€â”€ agent.py
â”‚   â”‚   â””â”€â”€ train.py
â”‚   â”œâ”€â”€ Actor_Critic/             # Actor-Critic from scratch
â”‚   â”‚   â”œâ”€â”€ env/
â”‚   â”‚   â”œâ”€â”€ agent.py
â”‚   â”‚   â””â”€â”€ train.py
â”‚   â””â”€â”€ PPO/                      # PPO/SAC via stable-baselines3
â”‚       â”œâ”€â”€ env/
â”‚       â””â”€â”€ train_sb3.py
â”‚
â”œâ”€â”€ MADDPG/                        # Custom project extension
â”‚   â”œâ”€â”€ Distill.py                 # Distillation logic
â”‚   â”œâ”€â”€ GlobalAgent.py             # Ensemble + distillation control
â”‚   â”œâ”€â”€ MADDPG.py                  # Multi-agent training loop
â”‚   â”œâ”€â”€ MultiAgent.py              # Per-agent logic
â”‚   â”œâ”€â”€ Networks.py                # Actor and Critic networks
â”‚   â”œâ”€â”€ Train.py                   # Entry point for training
â”‚   â”œâ”€â”€ test.py                    # Evaluation and testing
â”‚   â”œâ”€â”€ Tuning.py                  # Hyperparameter tuning
â”‚   â”œâ”€â”€ main.py                    # Script dispatcher
â”‚   â”œâ”€â”€ RL_Multi_Agent/            # Training data or configs
â”‚   â”œâ”€â”€ tuning_results/            # Saved tuning outputs
â”‚   â”œâ”€â”€ vmas/                      # VMAS environments
â”‚   â””â”€â”€ wandb/                     # Weights & Biases logs
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

---

## Official Tasks (in `/Tasks/`)

These follow the structure and requirements described in the official project guidelines:

| Task | Description |
|------|-------------|
| **1** | Explore the MuJoCo Hopper environment |
| **2** | Implement REINFORCE (with/without baseline) |
| **3** | Implement Actor-Critic from scratch |
| **4** | Implement PPO using Stable-Baselines3 |
| **5** | Evaluate sim-to-sim transfer (sourceâ†’target) |
| **6** | Uniform Domain Randomization (UDR) for Hopper |

Run REINFORCE:

```bash
cd Tasks/REINFORCE
python train.py

Run Actor-Critic:

cd Tasks/Actor_Critic
python train.py

Run PPO:

cd Tasks/PPO
python train_sb3.py --algo ppo --domain source


â¸»

Project Extension â€“ Multi-Agent MADDPG

In the `MADDPG/` folder you will find a custom extension implementing:

    - Multi-Agent Deep Deterministic Policy Gradient (MADDPG)
    - Centralized critic and decentralized actors
    - Ensemble learning: multiple policies per agent
    - Policy distillation into compact deployable policies
    - Uniform Domain Randomization (UDR) to enhance robustness
    - Tested in the VMAS `Balance` cooperative environment

Run MADDPG training:

cd MADDPG
python Train.py --env_name Balance --n_agents 2 --n_episodes 1000000


â¸»

Highlights
	â€¢	From-scratch implementation of REINFORCE and Actor-Critic
	â€¢	Use of SB3 to train PPO and SAC
	â€¢	Sim-to-sim transfer testing (source vs. target domain)
	â€¢	Uniform Domain Randomization on Hopper dynamics
	â€¢	Multi-agent coordination with MADDPG
	â€¢	Robustness via policy ensembles and distillation
	â€¢	Integration with Weights & Biases (wandb)

â¸»

Authors

| Name                              | Student ID     | Email                          | Department                    |
|-----------------------------------|----------------|--------------------------------|-------------------------------|
| Francesco Mastrosimone            | s348159        | s348159@studenti.polito.it     | DAUIN â€“ Politecnico di Torino |
| Brian Facundo Condorpocco Morales | s346581        | s346581@studenti.polito.it     | DAUIN â€“ Politecnico di Torino |
| Salvatore Nocita                  | s346378        | s346378@studenti.polito.it     | DAUIN â€“ Politecnico di Torino |
| Luciano Scarpino                  | s346205        | s346205@studenti.polito.it     | DAUIN â€“ Politecnico di Torino |

---

Third-Party Licenses

This repository makes use of the [Vectorized Multi-Agent Simulator (VMAS)](https://github.com/proroklab/VectorizedMultiAgentSimulator) developed by the Multi-Agent & Heterogeneous Systems Lab (Prorok Lab), University of Cambridge.

VMAS is licensed under the **MIT License**.  
Â© 2022 Prorok Lab.

> Permission is hereby granted, free of charge, to any person obtaining a copy  
> of this software and associated documentation files (the "Software"), to deal  
> in the Software without restriction, including without limitation the rights  
> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell  
> copies of the Software, and to permit persons to whom the Software is  
> furnished to do so, subject to the following conditions: [...]

Full license available [here](https://github.com/proroklab/VectorizedMultiAgentSimulator/blob/main/LICENSE).